{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc465c-6a71-4497-aa8f-609ccd2ce23e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, TrainingArguments, Trainer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from PIL import Image\n",
    "from accelerate import Accelerator\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "def print_gpu():\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(\"当前卡型号\", props.name)  # 会显示你的第 4 张卡型号\n",
    "    for cuda_id in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(cuda_id)\n",
    "        total = props.total_memory / 1024**3\n",
    "        allocated = torch.cuda.memory_allocated(cuda_id) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(cuda_id) / 1024**3\n",
    "        free = total - reserved\n",
    "        print(f\"GPU {cuda_id}:\")\n",
    "        print(f\"  总显存: {total:.2f} GB\")\n",
    "        print(f\"  已分配显存: {allocated:.2f} GB\")\n",
    "        print(f\"  已缓存显存: {reserved:.2f} GB\")\n",
    "        print(f\"  空闲显存: {free:.2f} GB\")\n",
    "\n",
    "# torch.cuda.set_device(4)\n",
    "# 下面的代码需要修改，以适配不同的设备\n",
    "print_gpu()\n",
    "model_path = r\"/home/tsingtao/vl_finetune_train/ERNIE-4.5-VL-28B-A3B-Paddle\"\n",
    "data_file = r\"/home/tsingtao/vl_finetune_train/vl_finetune/sft_vl_train_shuffle.jsonl\"\n",
    "image_dir = r\"/home/tsingtao/vl_finetune_train/vl_finetune\"\n",
    "output_dir = \"output\"\n",
    "num_epochs = 10\n",
    "batch_size = 2\n",
    "gradient_accumulation_steps = 8\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# accelerator = Accelerator()\n",
    "# device = accelerator.device\n",
    "\n",
    "# device=\"cpu\"\n",
    "# 加载模型和处理器\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "print(model.device)\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# LoRA配置\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n",
    "lora_config = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf1711-97ee-49bb-afee-b91d1b397ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Union\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import GPUtil\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from transformers import TrainerCallback\n",
    "import traceback  \n",
    "\n",
    "# 显示显存占用，方便通过图查看显存占用\n",
    "class MemoryMonitor:\n",
    "    def __init__(self, delay=1, plot_interval=5):\n",
    "        self.delay = delay  # 更新时间\n",
    "        self.plot_interval = plot_interval  \n",
    "        self.keep_measuring = True\n",
    "        self.gpu_memory = []\n",
    "        self.timestamps = []\n",
    "        self.start_time = time.time()\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 5))\n",
    "        \n",
    "    def measure_memory(self):\n",
    "        while self.keep_measuring:\n",
    "            try:\n",
    "                # 这里使用torch查看缓存的显存来了解当前的显存占用\n",
    "                cuda_id = 0\n",
    "                allocated = torch.cuda.memory_allocated(cuda_id) / 1024**3  # GB\n",
    "                self.gpu_memory.append(allocated)\n",
    "                self.timestamps.append(time.time() - self.start_time)\n",
    "            \n",
    "                # 更新\n",
    "                if len(self.gpu_memory) % self.plot_interval == 0:\n",
    "                    self.update_plot()\n",
    "            except Exception as e:\n",
    "                print(f\"Memory monitoring error: {e}\")\n",
    "                \n",
    "            time.sleep(self.delay)\n",
    "    \n",
    "    def update_plot(self):\n",
    "        from IPython.display import display\n",
    "        \n",
    "        # 不用中文避免乱码\n",
    "        with plt.ioff():\n",
    "            self.ax.clear()\n",
    "            self.ax.plot(self.timestamps, self.gpu_memory, label='GPU Memory (GB)')\n",
    "            self.ax.set_xlabel('Time (s)')\n",
    "            self.ax.set_ylabel('Memory Usage (GB)')\n",
    "            self.ax.set_title('GPU Memory')\n",
    "            self.ax.legend()\n",
    "            self.ax.grid(True)\n",
    "            self.fig.tight_layout()\n",
    "            self.fig.canvas.draw_idle()\n",
    "        \n",
    "        # 使用matplotlib在notebook中展示\n",
    "        display(self.fig)\n",
    "    \n",
    "    # 新开线程实现绘制显存占用图\n",
    "    def start(self):\n",
    "        self.thread = threading.Thread(target=self.measure_memory)\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.keep_measuring = False\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join(timeout=1)\n",
    "        self.update_plot()\n",
    "\n",
    "class TeaDiseaseDataset(Dataset):\n",
    "    def __init__(self, json_file, image_dir, processor, max_length=1024):  # Reduced max_length\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # 加载json文件\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "        \n",
    "        # 图片文件夹\n",
    "        self.base_dir = image_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            # 获取图片\n",
    "            image_path = os.path.join(self.base_dir, item[\"image_info\"][0][\"image_url\"])\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            \n",
    "            # 信息\n",
    "            question = item[\"text_info\"][0][\"text\"]\n",
    "            answer = item[\"text_info\"][1][\"text\"]\n",
    "            \n",
    "            instruction = f\"请根据图片回答以下问题：{question}\"\n",
    "            full_text = instruction + answer\n",
    "\n",
    "            encoding = self.processor(\n",
    "                text=full_text,\n",
    "                images=image,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                max_length=self.max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            \n",
    "            input_ids = encoding.input_ids[0]\n",
    "            \n",
    "            if hasattr(encoding, 'attention_mask') and encoding.attention_mask is not None:\n",
    "                attention_mask = encoding.attention_mask[0]\n",
    "            else:\n",
    "                pad_token_id = self.processor.tokenizer.pad_token_id\n",
    "                attention_mask = (input_ids != pad_token_id).long()\n",
    "\n",
    "            instruction_encoding = self.processor(\n",
    "                text=instruction,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length, \n",
    "            )\n",
    "            instruction_len = instruction_encoding.input_ids.shape[1]\n",
    "            \n",
    "            # 省点内存\n",
    "            del instruction_encoding\n",
    "            \n",
    "            # 造label\n",
    "            labels = input_ids.clone()\n",
    "            labels[:instruction_len] = -100\n",
    "            \n",
    "            # mask\n",
    "            pad_token_id = self.processor.tokenizer.pad_token_id\n",
    "            labels[labels == pad_token_id] = -100\n",
    "            \n",
    "            # 获取pixel\n",
    "            pixel_values = None\n",
    "            if hasattr(encoding, \"pixel_values\"):\n",
    "                pixel_values = encoding.pixel_values[0]\n",
    "            \n",
    "            # 获取位置id\n",
    "            seq_length = input_ids.shape[0]\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long)\n",
    "            \n",
    "            if hasattr(encoding, \"token_type_ids\"):\n",
    "                token_type_ids = encoding.token_type_ids[0]\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(seq_length, dtype=torch.long)\n",
    "            \n",
    "            del encoding\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": attention_mask,\n",
    "                \"position_ids\": position_ids,\n",
    "                \"pixel_values\": pixel_values,\n",
    "                \"labels\": labels,\n",
    "                \"token_type_ids\": token_type_ids,\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"错误：\")\n",
    "            traceback_print_exc()\n",
    "            return self.__getitem__(max(0, idx-1))\n",
    "\n",
    "@dataclass\n",
    "class ErnieDataCollator:\n",
    "    def __call__(self, features: List[Dict[str, Union[torch.Tensor, None]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = {}\n",
    "        for key in [\"input_ids\", \"attention_mask\", \"position_ids\", \"labels\"]:\n",
    "            if key not in features[0]:\n",
    "                continue\n",
    "                \n",
    "            batch[key] = torch.stack([f[key] for f in features if f[key] is not None])\n",
    "\n",
    "        if \"pixel_values\" in features[0] and features[0][\"pixel_values\"] is not None:\n",
    "            batch[\"pixel_values\"] = torch.stack([f[\"pixel_values\"] for f in features if f[\"pixel_values\"] is not None])\n",
    "        \n",
    "        if \"token_type_ids\" in features[0] and features[0][\"token_type_ids\"] is not None:\n",
    "            batch[\"token_type_ids\"] = torch.stack([f[\"token_type_ids\"] for f in features if f[\"token_type_ids\"] is not None])\n",
    "            \n",
    "        return batch\n",
    "\n",
    "class ErnieTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        计算损失，ERNIE4.5-VL没给损失，需要我们自己构造\n",
    "        \"\"\"\n",
    "        # Extract inputs that the model needs for forward pass\n",
    "        input_dict = {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "            \"labels\": inputs[\"labels\"],\n",
    "        }\n",
    "        \n",
    " \n",
    "        if \"pixel_values\" in inputs:\n",
    "            input_dict[\"pixel_values\"] = inputs[\"pixel_values\"]\n",
    "        \n",
    "\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            token_type_ids = inputs[\"token_type_ids\"]\n",
    "            input_ids_length = inputs[\"input_ids\"].shape[1]\n",
    "            \n",
    "            if token_type_ids.shape[1] == input_ids_length:\n",
    "                last_token = token_type_ids[:, -1].unsqueeze(1)\n",
    "                token_type_ids = torch.cat([token_type_ids, last_token], dim=1)\n",
    "            input_dict[\"token_type_ids\"] = token_type_ids\n",
    "\n",
    "        if \"position_ids\" in inputs:\n",
    "            input_dict[\"position_ids\"] = inputs[\"position_ids\"]\n",
    "            \n",
    "        outputs = model(**input_dict)\n",
    "        \n",
    "        if \"loss\" not in outputs:\n",
    "            logits = outputs.logits\n",
    "            labels = inputs[\"labels\"]\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = loss_fct(\n",
    "                shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                shift_labels.view(-1)\n",
    "            )\n",
    "            outputs = {\"loss\": loss, \"logits\": logits}\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return (outputs[\"loss\"], outputs) if return_outputs else outputs[\"loss\"]\n",
    "\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        output = super().training_step(*args, **kwargs)\n",
    "        \n",
    "        # 缓存清空，每10步一次，避免oom\n",
    "        if self.state.global_step % 10 == 0:  # Every 10 steps\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        return output\n",
    "\n",
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            print(f\"Step {state.global_step}: {logs}\")\n",
    "\n",
    "def train_model(data_file, image_dir, processor, model, output_dir, \n",
    "               num_epochs=3, learning_rate=2e-5, batch_size=1, \n",
    "               gradient_accumulation_steps=4, max_length=1024):\n",
    "    \"\"\"\n",
    "    训练主函数\n",
    "    \"\"\"\n",
    "    memory_monitor = MemoryMonitor(delay=2)\n",
    "    memory_monitor.start()\n",
    "\n",
    "    try:\n",
    "        dataset = TeaDiseaseDataset(data_file, image_dir, processor, max_length=max_length)\n",
    "        print(f\"训练集大小: {len(dataset)}\")\n",
    "        collect_fn = ErnieDataCollator()\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=0.01,\n",
    "            warmup_ratio=0.03,\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            save_strategy=\"epoch\",\n",
    "            logging_steps=10,\n",
    "            fp16=True,\n",
    "            gradient_checkpointing=False,  # 这个一定不能用，ERNIE多模态模型不支持\n",
    "            report_to=\"tensorboard\",\n",
    "            dataloader_pin_memory=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            save_total_limit=1,\n",
    "            eval_steps=None,\n",
    "        )\n",
    "        printer_callback = PrinterCallback()\n",
    "\n",
    "        trainer = ErnieTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset,\n",
    "            data_collator=collect_fn,\n",
    "            callbacks=[printer_callback]\n",
    "        )\n",
    "        \n",
    "        print(\"开练...\")\n",
    "        trainer.train()\n",
    "\n",
    "        model.save_pretrained(os.path.join(output_dir, \"final_model\"))\n",
    "        processor.save_pretrained(os.path.join(output_dir, \"final_processor\"))\n",
    "        print(f\"保存于{os.path.join(output_dir, 'final_model')}\")\n",
    "\n",
    "        \n",
    "    finally:\n",
    "        memory_monitor.stop()\n",
    "\n",
    "train_model(\n",
    "    data_file=data_file,\n",
    "    image_dir=image_dir, \n",
    "    processor=processor, \n",
    "    model=model, \n",
    "    output_dir=output_dir,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=1,\n",
    "    gradient_accumulation_steps=8,  # 设置了8次就会梯度累计然后清空\n",
    "    max_length=1024 \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
